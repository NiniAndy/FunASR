{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path= \"/ssd/zhuang/code/FunASR/examples/kespeech/paraformer/exp/baseline_paraformer_conformer_12e_6d_2048_256_zh_char_SW-LoRA-FT/model.pt.avg10\"\n",
    "model = torch.load(model_path, map_location='cpu')[\"state_dict\"]\n",
    "\n",
    "ori_model_path=\"/ssd/zhuang/code/FunASR/examples/aishell/paraformer/exp/speech_paraformer_asr_nat-aishell1-pytorch/model.pb\"\n",
    "ori_model = torch.load(ori_model_path, map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.embed.conv.0.weight torch.Size([256, 1, 3, 3])\n",
      "encoder.embed.conv.0.bias torch.Size([256])\n",
      "encoder.embed.conv.2.weight torch.Size([256, 256, 3, 3])\n",
      "encoder.embed.conv.2.bias torch.Size([256])\n",
      "encoder.embed.out.0.weight torch.Size([256, 4864])\n",
      "encoder.embed.out.0.bias torch.Size([256])\n",
      "encoder.encoders.0.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.0.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.0.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.0.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.0.self_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.0.self_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.0.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.0.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.0.self_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.0.self_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.0.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.0.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.0.self_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.0.self_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.0.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.0.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.0.self_attn.linear_out.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.0.self_attn.linear_out.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.0.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.0.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.0.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.0.feed_forward.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.0.feed_forward.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.0.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.0.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.0.feed_forward.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.0.feed_forward.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.0.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.0.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.0.feed_forward_macaron.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.0.feed_forward_macaron.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.0.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.0.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.0.feed_forward_macaron.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.0.feed_forward_macaron.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.0.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.0.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.0.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.0.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.0.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.0.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.0.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.0.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.0.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.0.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.0.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.0.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.0.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.0.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.0.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.0.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.0.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.0.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.0.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.0.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.0.norm_final.bias torch.Size([256])\n",
      "encoder.encoders.1.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.1.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.1.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.1.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.1.self_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.1.self_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.1.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.1.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.1.self_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.1.self_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.1.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.1.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.1.self_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.1.self_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.1.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.1.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.1.self_attn.linear_out.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.1.self_attn.linear_out.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.1.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.1.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.1.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.1.feed_forward.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.1.feed_forward.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.1.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.1.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.1.feed_forward.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.1.feed_forward.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.1.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.1.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.1.feed_forward_macaron.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.1.feed_forward_macaron.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.1.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.1.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.1.feed_forward_macaron.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.1.feed_forward_macaron.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.1.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.1.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.1.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.1.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.1.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.1.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.1.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.1.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.1.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.1.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.1.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.1.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.1.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.1.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.1.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.1.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.1.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.1.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.1.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.1.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.1.norm_final.bias torch.Size([256])\n",
      "encoder.encoders.2.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.2.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.2.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.2.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.2.self_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.2.self_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.2.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.2.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.2.self_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.2.self_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.2.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.2.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.2.self_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.2.self_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.2.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.2.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.2.self_attn.linear_out.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.2.self_attn.linear_out.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.2.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.2.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.2.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.2.feed_forward.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.2.feed_forward.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.2.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.2.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.2.feed_forward.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.2.feed_forward.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.2.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.2.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.2.feed_forward_macaron.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.2.feed_forward_macaron.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.2.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.2.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.2.feed_forward_macaron.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.2.feed_forward_macaron.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.2.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.2.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.2.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.2.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.2.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.2.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.2.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.2.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.2.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.2.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.2.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.2.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.2.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.2.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.2.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.2.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.2.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.2.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.2.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.2.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.2.norm_final.bias torch.Size([256])\n",
      "encoder.encoders.3.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.3.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.3.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.3.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.3.self_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.3.self_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.3.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.3.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.3.self_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.3.self_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.3.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.3.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.3.self_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.3.self_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.3.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.3.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.3.self_attn.linear_out.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.3.self_attn.linear_out.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.3.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.3.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.3.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.3.feed_forward.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.3.feed_forward.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.3.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.3.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.3.feed_forward.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.3.feed_forward.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.3.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.3.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.3.feed_forward_macaron.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.3.feed_forward_macaron.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.3.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.3.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.3.feed_forward_macaron.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.3.feed_forward_macaron.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.3.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.3.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.3.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.3.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.3.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.3.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.3.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.3.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.3.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.3.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.3.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.3.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.3.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.3.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.3.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.3.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.3.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.3.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.3.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.3.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.3.norm_final.bias torch.Size([256])\n",
      "encoder.encoders.4.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.4.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.4.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.4.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.4.self_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.4.self_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.4.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.4.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.4.self_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.4.self_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.4.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.4.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.4.self_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.4.self_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.4.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.4.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.4.self_attn.linear_out.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.4.self_attn.linear_out.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.4.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.4.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.4.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.4.feed_forward.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.4.feed_forward.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.4.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.4.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.4.feed_forward.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.4.feed_forward.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.4.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.4.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.4.feed_forward_macaron.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.4.feed_forward_macaron.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.4.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.4.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.4.feed_forward_macaron.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.4.feed_forward_macaron.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.4.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.4.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.4.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.4.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.4.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.4.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.4.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.4.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.4.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.4.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.4.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.4.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.4.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.4.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.4.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.4.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.4.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.4.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.4.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.4.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.4.norm_final.bias torch.Size([256])\n",
      "encoder.encoders.5.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.5.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.5.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.5.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.5.self_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.5.self_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.5.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.5.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.5.self_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.5.self_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.5.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.5.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.5.self_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.5.self_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.5.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.5.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.5.self_attn.linear_out.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.5.self_attn.linear_out.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.5.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.5.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.5.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.5.feed_forward.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.5.feed_forward.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.5.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.5.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.5.feed_forward.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.5.feed_forward.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.5.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.5.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.5.feed_forward_macaron.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.5.feed_forward_macaron.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.5.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.5.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.5.feed_forward_macaron.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.5.feed_forward_macaron.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.5.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.5.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.5.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.5.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.5.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.5.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.5.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.5.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.5.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.5.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.5.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.5.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.5.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.5.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.5.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.5.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.5.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.5.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.5.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.5.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.5.norm_final.bias torch.Size([256])\n",
      "encoder.encoders.6.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.6.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.6.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.6.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.6.self_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.6.self_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.6.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.6.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.6.self_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.6.self_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.6.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.6.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.6.self_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.6.self_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.6.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.6.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.6.self_attn.linear_out.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.6.self_attn.linear_out.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.6.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.6.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.6.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.6.feed_forward.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.6.feed_forward.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.6.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.6.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.6.feed_forward.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.6.feed_forward.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.6.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.6.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.6.feed_forward_macaron.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.6.feed_forward_macaron.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.6.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.6.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.6.feed_forward_macaron.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.6.feed_forward_macaron.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.6.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.6.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.6.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.6.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.6.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.6.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.6.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.6.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.6.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.6.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.6.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.6.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.6.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.6.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.6.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.6.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.6.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.6.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.6.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.6.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.6.norm_final.bias torch.Size([256])\n",
      "encoder.encoders.7.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.7.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.7.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.7.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.7.self_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.7.self_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.7.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.7.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.7.self_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.7.self_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.7.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.7.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.7.self_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.7.self_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.7.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.7.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.7.self_attn.linear_out.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.7.self_attn.linear_out.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.7.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.7.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.7.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.7.feed_forward.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.7.feed_forward.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.7.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.7.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.7.feed_forward.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.7.feed_forward.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.7.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.7.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.7.feed_forward_macaron.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.7.feed_forward_macaron.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.7.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.7.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.7.feed_forward_macaron.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.7.feed_forward_macaron.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.7.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.7.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.7.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.7.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.7.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.7.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.7.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.7.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.7.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.7.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.7.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.7.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.7.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.7.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.7.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.7.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.7.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.7.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.7.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.7.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.7.norm_final.bias torch.Size([256])\n",
      "encoder.encoders.8.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.8.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.8.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.8.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.8.self_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.8.self_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.8.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.8.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.8.self_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.8.self_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.8.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.8.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.8.self_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.8.self_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.8.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.8.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.8.self_attn.linear_out.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.8.self_attn.linear_out.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.8.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.8.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.8.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.8.feed_forward.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.8.feed_forward.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.8.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.8.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.8.feed_forward.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.8.feed_forward.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.8.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.8.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.8.feed_forward_macaron.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.8.feed_forward_macaron.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.8.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.8.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.8.feed_forward_macaron.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.8.feed_forward_macaron.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.8.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.8.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.8.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.8.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.8.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.8.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.8.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.8.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.8.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.8.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.8.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.8.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.8.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.8.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.8.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.8.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.8.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.8.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.8.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.8.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.8.norm_final.bias torch.Size([256])\n",
      "encoder.encoders.9.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.9.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.9.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.9.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.9.self_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.9.self_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.9.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.9.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.9.self_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.9.self_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.9.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.9.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.9.self_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.9.self_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.9.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.9.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.9.self_attn.linear_out.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.9.self_attn.linear_out.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.9.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.9.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.9.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.9.feed_forward.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.9.feed_forward.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.9.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.9.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.9.feed_forward.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.9.feed_forward.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.9.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.9.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.9.feed_forward_macaron.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.9.feed_forward_macaron.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.9.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.9.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.9.feed_forward_macaron.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.9.feed_forward_macaron.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.9.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.9.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.9.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.9.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.9.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.9.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.9.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.9.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.9.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.9.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.9.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.9.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.9.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.9.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.9.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.9.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.9.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.9.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.9.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.9.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.9.norm_final.bias torch.Size([256])\n",
      "encoder.encoders.10.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.10.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.10.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.10.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.10.self_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.10.self_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.10.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.10.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.10.self_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.10.self_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.10.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.10.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.10.self_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.10.self_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.10.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.10.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.10.self_attn.linear_out.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.10.self_attn.linear_out.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.10.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.10.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.10.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.10.feed_forward.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.10.feed_forward.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.10.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.10.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.10.feed_forward.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.10.feed_forward.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.10.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.10.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.10.feed_forward_macaron.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.10.feed_forward_macaron.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.10.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.10.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.10.feed_forward_macaron.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.10.feed_forward_macaron.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.10.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.10.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.10.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.10.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.10.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.10.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.10.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.10.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.10.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.10.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.10.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.10.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.10.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.10.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.10.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.10.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.10.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.10.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.10.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.10.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.10.norm_final.bias torch.Size([256])\n",
      "encoder.encoders.11.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.11.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.11.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.11.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.11.self_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.11.self_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.11.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.11.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.11.self_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.11.self_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.11.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.11.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.11.self_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.11.self_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.11.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.11.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.11.self_attn.linear_out.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.11.self_attn.linear_out.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.11.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.11.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.11.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.11.feed_forward.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.11.feed_forward.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.11.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.11.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.11.feed_forward.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.11.feed_forward.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.11.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.11.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.11.feed_forward_macaron.w_1.lora_A torch.Size([32, 256])\n",
      "encoder.encoders.11.feed_forward_macaron.w_1.lora_B torch.Size([2048, 32])\n",
      "encoder.encoders.11.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.11.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.11.feed_forward_macaron.w_2.lora_A torch.Size([32, 2048])\n",
      "encoder.encoders.11.feed_forward_macaron.w_2.lora_B torch.Size([256, 32])\n",
      "encoder.encoders.11.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.11.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.11.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.11.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.11.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.11.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.11.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.11.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.11.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.11.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.11.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.11.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.11.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.11.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.11.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.11.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.11.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.11.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.11.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.11.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.11.norm_final.bias torch.Size([256])\n",
      "encoder.after_norm.weight torch.Size([256])\n",
      "encoder.after_norm.bias torch.Size([256])\n",
      "decoder.embed.0.weight torch.Size([4234, 256])\n",
      "decoder.after_norm.weight torch.Size([256])\n",
      "decoder.after_norm.bias torch.Size([256])\n",
      "decoder.output_layer.weight torch.Size([4234, 256])\n",
      "decoder.output_layer.bias torch.Size([4234])\n",
      "decoder.decoders.0.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.0.self_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.0.self_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.0.self_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.0.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.0.self_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.0.self_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.0.self_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.0.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.0.self_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.0.self_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.0.self_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.0.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.0.self_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.0.src_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.0.src_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.0.src_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.0.src_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.0.src_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.0.src_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.0.src_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.0.src_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.0.src_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.0.src_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.0.src_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.0.src_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.0.src_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.0.src_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.0.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "decoder.decoders.0.feed_forward.w_1.bias torch.Size([2048])\n",
      "decoder.decoders.0.feed_forward.w_1.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.0.feed_forward.w_1.lora_B torch.Size([2048, 32])\n",
      "decoder.decoders.0.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "decoder.decoders.0.feed_forward.w_2.bias torch.Size([256])\n",
      "decoder.decoders.0.feed_forward.w_2.lora_A torch.Size([32, 2048])\n",
      "decoder.decoders.0.feed_forward.w_2.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.0.norm1.weight torch.Size([256])\n",
      "decoder.decoders.0.norm1.bias torch.Size([256])\n",
      "decoder.decoders.0.norm2.weight torch.Size([256])\n",
      "decoder.decoders.0.norm2.bias torch.Size([256])\n",
      "decoder.decoders.0.norm3.weight torch.Size([256])\n",
      "decoder.decoders.0.norm3.bias torch.Size([256])\n",
      "decoder.decoders.1.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.1.self_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.1.self_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.1.self_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.1.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.1.self_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.1.self_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.1.self_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.1.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.1.self_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.1.self_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.1.self_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.1.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.1.self_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.1.src_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.1.src_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.1.src_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.1.src_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.1.src_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.1.src_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.1.src_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.1.src_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.1.src_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.1.src_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.1.src_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.1.src_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.1.src_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.1.src_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.1.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "decoder.decoders.1.feed_forward.w_1.bias torch.Size([2048])\n",
      "decoder.decoders.1.feed_forward.w_1.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.1.feed_forward.w_1.lora_B torch.Size([2048, 32])\n",
      "decoder.decoders.1.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "decoder.decoders.1.feed_forward.w_2.bias torch.Size([256])\n",
      "decoder.decoders.1.feed_forward.w_2.lora_A torch.Size([32, 2048])\n",
      "decoder.decoders.1.feed_forward.w_2.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.1.norm1.weight torch.Size([256])\n",
      "decoder.decoders.1.norm1.bias torch.Size([256])\n",
      "decoder.decoders.1.norm2.weight torch.Size([256])\n",
      "decoder.decoders.1.norm2.bias torch.Size([256])\n",
      "decoder.decoders.1.norm3.weight torch.Size([256])\n",
      "decoder.decoders.1.norm3.bias torch.Size([256])\n",
      "decoder.decoders.2.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.2.self_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.2.self_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.2.self_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.2.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.2.self_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.2.self_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.2.self_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.2.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.2.self_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.2.self_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.2.self_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.2.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.2.self_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.2.src_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.2.src_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.2.src_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.2.src_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.2.src_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.2.src_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.2.src_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.2.src_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.2.src_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.2.src_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.2.src_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.2.src_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.2.src_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.2.src_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.2.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "decoder.decoders.2.feed_forward.w_1.bias torch.Size([2048])\n",
      "decoder.decoders.2.feed_forward.w_1.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.2.feed_forward.w_1.lora_B torch.Size([2048, 32])\n",
      "decoder.decoders.2.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "decoder.decoders.2.feed_forward.w_2.bias torch.Size([256])\n",
      "decoder.decoders.2.feed_forward.w_2.lora_A torch.Size([32, 2048])\n",
      "decoder.decoders.2.feed_forward.w_2.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.2.norm1.weight torch.Size([256])\n",
      "decoder.decoders.2.norm1.bias torch.Size([256])\n",
      "decoder.decoders.2.norm2.weight torch.Size([256])\n",
      "decoder.decoders.2.norm2.bias torch.Size([256])\n",
      "decoder.decoders.2.norm3.weight torch.Size([256])\n",
      "decoder.decoders.2.norm3.bias torch.Size([256])\n",
      "decoder.decoders.3.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.3.self_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.3.self_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.3.self_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.3.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.3.self_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.3.self_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.3.self_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.3.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.3.self_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.3.self_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.3.self_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.3.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.3.self_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.3.src_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.3.src_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.3.src_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.3.src_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.3.src_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.3.src_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.3.src_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.3.src_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.3.src_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.3.src_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.3.src_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.3.src_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.3.src_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.3.src_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.3.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "decoder.decoders.3.feed_forward.w_1.bias torch.Size([2048])\n",
      "decoder.decoders.3.feed_forward.w_1.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.3.feed_forward.w_1.lora_B torch.Size([2048, 32])\n",
      "decoder.decoders.3.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "decoder.decoders.3.feed_forward.w_2.bias torch.Size([256])\n",
      "decoder.decoders.3.feed_forward.w_2.lora_A torch.Size([32, 2048])\n",
      "decoder.decoders.3.feed_forward.w_2.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.3.norm1.weight torch.Size([256])\n",
      "decoder.decoders.3.norm1.bias torch.Size([256])\n",
      "decoder.decoders.3.norm2.weight torch.Size([256])\n",
      "decoder.decoders.3.norm2.bias torch.Size([256])\n",
      "decoder.decoders.3.norm3.weight torch.Size([256])\n",
      "decoder.decoders.3.norm3.bias torch.Size([256])\n",
      "decoder.decoders.4.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.4.self_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.4.self_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.4.self_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.4.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.4.self_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.4.self_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.4.self_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.4.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.4.self_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.4.self_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.4.self_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.4.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.4.self_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.4.src_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.4.src_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.4.src_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.4.src_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.4.src_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.4.src_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.4.src_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.4.src_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.4.src_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.4.src_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.4.src_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.4.src_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.4.src_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.4.src_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.4.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "decoder.decoders.4.feed_forward.w_1.bias torch.Size([2048])\n",
      "decoder.decoders.4.feed_forward.w_1.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.4.feed_forward.w_1.lora_B torch.Size([2048, 32])\n",
      "decoder.decoders.4.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "decoder.decoders.4.feed_forward.w_2.bias torch.Size([256])\n",
      "decoder.decoders.4.feed_forward.w_2.lora_A torch.Size([32, 2048])\n",
      "decoder.decoders.4.feed_forward.w_2.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.4.norm1.weight torch.Size([256])\n",
      "decoder.decoders.4.norm1.bias torch.Size([256])\n",
      "decoder.decoders.4.norm2.weight torch.Size([256])\n",
      "decoder.decoders.4.norm2.bias torch.Size([256])\n",
      "decoder.decoders.4.norm3.weight torch.Size([256])\n",
      "decoder.decoders.4.norm3.bias torch.Size([256])\n",
      "decoder.decoders.5.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.5.self_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.5.self_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.5.self_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.5.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.5.self_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.5.self_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.5.self_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.5.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.5.self_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.5.self_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.5.self_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.5.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.5.self_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.5.src_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.5.src_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.5.src_attn.linear_q.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.5.src_attn.linear_q.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.5.src_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.5.src_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.5.src_attn.linear_k.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.5.src_attn.linear_k.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.5.src_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.5.src_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.5.src_attn.linear_v.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.5.src_attn.linear_v.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.5.src_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.5.src_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.5.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "decoder.decoders.5.feed_forward.w_1.bias torch.Size([2048])\n",
      "decoder.decoders.5.feed_forward.w_1.lora_A torch.Size([32, 256])\n",
      "decoder.decoders.5.feed_forward.w_1.lora_B torch.Size([2048, 32])\n",
      "decoder.decoders.5.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "decoder.decoders.5.feed_forward.w_2.bias torch.Size([256])\n",
      "decoder.decoders.5.feed_forward.w_2.lora_A torch.Size([32, 2048])\n",
      "decoder.decoders.5.feed_forward.w_2.lora_B torch.Size([256, 32])\n",
      "decoder.decoders.5.norm1.weight torch.Size([256])\n",
      "decoder.decoders.5.norm1.bias torch.Size([256])\n",
      "decoder.decoders.5.norm2.weight torch.Size([256])\n",
      "decoder.decoders.5.norm2.bias torch.Size([256])\n",
      "decoder.decoders.5.norm3.weight torch.Size([256])\n",
      "decoder.decoders.5.norm3.bias torch.Size([256])\n",
      "ctc.ctc_lo.weight torch.Size([4234, 256])\n",
      "ctc.ctc_lo.bias torch.Size([4234])\n",
      "predictor.cif_conv1d.weight torch.Size([256, 1, 3])\n",
      "predictor.cif_conv1d.bias torch.Size([256])\n",
      "predictor.cif_output.weight torch.Size([1, 256])\n",
      "predictor.cif_output.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for k, v in model.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.embed.conv.0.weight torch.Size([256, 1, 3, 3])\n",
      "encoder.embed.conv.0.bias torch.Size([256])\n",
      "encoder.embed.conv.2.weight torch.Size([256, 256, 3, 3])\n",
      "encoder.embed.conv.2.bias torch.Size([256])\n",
      "encoder.embed.out.0.weight torch.Size([256, 4864])\n",
      "encoder.embed.out.0.bias torch.Size([256])\n",
      "encoder.encoders.0.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.0.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.0.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.0.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.0.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.0.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.0.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.0.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.0.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.0.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.0.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.0.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.0.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.0.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.0.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.0.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.0.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.0.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.0.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.0.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.0.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.0.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.0.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.0.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.0.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.0.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.0.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.0.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.0.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.0.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.0.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.0.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.0.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.0.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.0.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.0.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.0.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.0.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.0.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.0.norm_final.bias torch.Size([256])\n",
      "encoder.encoders.1.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.1.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.1.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.1.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.1.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.1.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.1.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.1.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.1.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.1.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.1.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.1.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.1.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.1.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.1.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.1.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.1.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.1.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.1.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.1.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.1.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.1.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.1.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.1.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.1.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.1.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.1.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.1.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.1.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.1.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.1.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.1.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.1.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.1.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.1.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.1.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.1.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.1.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.1.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.1.norm_final.bias torch.Size([256])\n",
      "encoder.encoders.2.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.2.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.2.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.2.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.2.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.2.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.2.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.2.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.2.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.2.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.2.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.2.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.2.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.2.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.2.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.2.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.2.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.2.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.2.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.2.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.2.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.2.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.2.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.2.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.2.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.2.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.2.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.2.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.2.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.2.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.2.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.2.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.2.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.2.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.2.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.2.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.2.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.2.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.2.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.2.norm_final.bias torch.Size([256])\n",
      "encoder.encoders.3.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.3.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.3.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.3.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.3.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.3.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.3.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.3.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.3.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.3.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.3.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.3.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.3.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.3.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.3.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.3.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.3.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.3.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.3.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.3.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.3.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.3.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.3.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.3.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.3.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.3.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.3.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.3.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.3.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.3.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.3.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.3.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.3.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.3.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.3.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.3.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.3.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.3.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.3.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.3.norm_final.bias torch.Size([256])\n",
      "encoder.encoders.4.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.4.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.4.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.4.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.4.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.4.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.4.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.4.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.4.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.4.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.4.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.4.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.4.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.4.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.4.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.4.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.4.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.4.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.4.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.4.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.4.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.4.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.4.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.4.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.4.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.4.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.4.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.4.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.4.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.4.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.4.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.4.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.4.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.4.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.4.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.4.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.4.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.4.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.4.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.4.norm_final.bias torch.Size([256])\n",
      "encoder.encoders.5.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.5.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.5.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.5.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.5.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.5.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.5.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.5.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.5.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.5.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.5.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.5.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.5.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.5.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.5.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.5.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.5.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.5.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.5.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.5.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.5.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.5.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.5.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.5.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.5.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.5.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.5.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.5.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.5.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.5.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.5.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.5.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.5.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.5.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.5.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.5.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.5.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.5.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.5.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.5.norm_final.bias torch.Size([256])\n",
      "encoder.encoders.6.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.6.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.6.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.6.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.6.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.6.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.6.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.6.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.6.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.6.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.6.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.6.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.6.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.6.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.6.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.6.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.6.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.6.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.6.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.6.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.6.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.6.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.6.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.6.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.6.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.6.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.6.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.6.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.6.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.6.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.6.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.6.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.6.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.6.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.6.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.6.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.6.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.6.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.6.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.6.norm_final.bias torch.Size([256])\n",
      "encoder.encoders.7.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.7.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.7.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.7.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.7.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.7.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.7.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.7.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.7.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.7.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.7.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.7.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.7.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.7.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.7.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.7.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.7.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.7.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.7.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.7.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.7.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.7.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.7.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.7.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.7.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.7.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.7.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.7.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.7.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.7.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.7.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.7.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.7.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.7.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.7.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.7.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.7.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.7.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.7.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.7.norm_final.bias torch.Size([256])\n",
      "encoder.encoders.8.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.8.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.8.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.8.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.8.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.8.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.8.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.8.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.8.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.8.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.8.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.8.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.8.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.8.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.8.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.8.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.8.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.8.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.8.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.8.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.8.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.8.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.8.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.8.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.8.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.8.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.8.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.8.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.8.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.8.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.8.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.8.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.8.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.8.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.8.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.8.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.8.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.8.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.8.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.8.norm_final.bias torch.Size([256])\n",
      "encoder.encoders.9.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.9.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.9.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.9.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.9.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.9.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.9.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.9.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.9.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.9.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.9.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.9.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.9.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.9.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.9.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.9.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.9.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.9.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.9.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.9.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.9.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.9.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.9.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.9.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.9.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.9.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.9.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.9.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.9.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.9.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.9.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.9.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.9.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.9.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.9.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.9.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.9.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.9.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.9.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.9.norm_final.bias torch.Size([256])\n",
      "encoder.encoders.10.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.10.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.10.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.10.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.10.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.10.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.10.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.10.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.10.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.10.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.10.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.10.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.10.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.10.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.10.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.10.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.10.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.10.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.10.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.10.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.10.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.10.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.10.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.10.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.10.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.10.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.10.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.10.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.10.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.10.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.10.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.10.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.10.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.10.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.10.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.10.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.10.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.10.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.10.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.10.norm_final.bias torch.Size([256])\n",
      "encoder.encoders.11.self_attn.pos_bias_u torch.Size([4, 64])\n",
      "encoder.encoders.11.self_attn.pos_bias_v torch.Size([4, 64])\n",
      "encoder.encoders.11.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "encoder.encoders.11.self_attn.linear_q.bias torch.Size([256])\n",
      "encoder.encoders.11.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "encoder.encoders.11.self_attn.linear_k.bias torch.Size([256])\n",
      "encoder.encoders.11.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "encoder.encoders.11.self_attn.linear_v.bias torch.Size([256])\n",
      "encoder.encoders.11.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "encoder.encoders.11.self_attn.linear_out.bias torch.Size([256])\n",
      "encoder.encoders.11.self_attn.linear_pos.weight torch.Size([256, 256])\n",
      "encoder.encoders.11.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.11.feed_forward.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.11.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.11.feed_forward.w_2.bias torch.Size([256])\n",
      "encoder.encoders.11.feed_forward_macaron.w_1.weight torch.Size([2048, 256])\n",
      "encoder.encoders.11.feed_forward_macaron.w_1.bias torch.Size([2048])\n",
      "encoder.encoders.11.feed_forward_macaron.w_2.weight torch.Size([256, 2048])\n",
      "encoder.encoders.11.feed_forward_macaron.w_2.bias torch.Size([256])\n",
      "encoder.encoders.11.conv_module.pointwise_conv1.weight torch.Size([512, 256, 1])\n",
      "encoder.encoders.11.conv_module.pointwise_conv1.bias torch.Size([512])\n",
      "encoder.encoders.11.conv_module.depthwise_conv.weight torch.Size([256, 1, 15])\n",
      "encoder.encoders.11.conv_module.depthwise_conv.bias torch.Size([256])\n",
      "encoder.encoders.11.conv_module.norm.weight torch.Size([256])\n",
      "encoder.encoders.11.conv_module.norm.bias torch.Size([256])\n",
      "encoder.encoders.11.conv_module.norm.running_mean torch.Size([256])\n",
      "encoder.encoders.11.conv_module.norm.running_var torch.Size([256])\n",
      "encoder.encoders.11.conv_module.norm.num_batches_tracked torch.Size([])\n",
      "encoder.encoders.11.conv_module.pointwise_conv2.weight torch.Size([256, 256, 1])\n",
      "encoder.encoders.11.conv_module.pointwise_conv2.bias torch.Size([256])\n",
      "encoder.encoders.11.norm_ff.weight torch.Size([256])\n",
      "encoder.encoders.11.norm_ff.bias torch.Size([256])\n",
      "encoder.encoders.11.norm_mha.weight torch.Size([256])\n",
      "encoder.encoders.11.norm_mha.bias torch.Size([256])\n",
      "encoder.encoders.11.norm_ff_macaron.weight torch.Size([256])\n",
      "encoder.encoders.11.norm_ff_macaron.bias torch.Size([256])\n",
      "encoder.encoders.11.norm_conv.weight torch.Size([256])\n",
      "encoder.encoders.11.norm_conv.bias torch.Size([256])\n",
      "encoder.encoders.11.norm_final.weight torch.Size([256])\n",
      "encoder.encoders.11.norm_final.bias torch.Size([256])\n",
      "encoder.after_norm.weight torch.Size([256])\n",
      "encoder.after_norm.bias torch.Size([256])\n",
      "decoder.embed.0.weight torch.Size([4234, 256])\n",
      "decoder.after_norm.weight torch.Size([256])\n",
      "decoder.after_norm.bias torch.Size([256])\n",
      "decoder.output_layer.weight torch.Size([4234, 256])\n",
      "decoder.output_layer.bias torch.Size([4234])\n",
      "decoder.decoders.0.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.0.self_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.0.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.0.self_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.0.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.0.self_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.0.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.0.self_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.0.src_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.0.src_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.0.src_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.0.src_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.0.src_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.0.src_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.0.src_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.0.src_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.0.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "decoder.decoders.0.feed_forward.w_1.bias torch.Size([2048])\n",
      "decoder.decoders.0.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "decoder.decoders.0.feed_forward.w_2.bias torch.Size([256])\n",
      "decoder.decoders.0.norm1.weight torch.Size([256])\n",
      "decoder.decoders.0.norm1.bias torch.Size([256])\n",
      "decoder.decoders.0.norm2.weight torch.Size([256])\n",
      "decoder.decoders.0.norm2.bias torch.Size([256])\n",
      "decoder.decoders.0.norm3.weight torch.Size([256])\n",
      "decoder.decoders.0.norm3.bias torch.Size([256])\n",
      "decoder.decoders.1.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.1.self_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.1.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.1.self_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.1.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.1.self_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.1.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.1.self_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.1.src_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.1.src_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.1.src_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.1.src_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.1.src_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.1.src_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.1.src_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.1.src_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.1.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "decoder.decoders.1.feed_forward.w_1.bias torch.Size([2048])\n",
      "decoder.decoders.1.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "decoder.decoders.1.feed_forward.w_2.bias torch.Size([256])\n",
      "decoder.decoders.1.norm1.weight torch.Size([256])\n",
      "decoder.decoders.1.norm1.bias torch.Size([256])\n",
      "decoder.decoders.1.norm2.weight torch.Size([256])\n",
      "decoder.decoders.1.norm2.bias torch.Size([256])\n",
      "decoder.decoders.1.norm3.weight torch.Size([256])\n",
      "decoder.decoders.1.norm3.bias torch.Size([256])\n",
      "decoder.decoders.2.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.2.self_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.2.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.2.self_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.2.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.2.self_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.2.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.2.self_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.2.src_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.2.src_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.2.src_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.2.src_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.2.src_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.2.src_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.2.src_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.2.src_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.2.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "decoder.decoders.2.feed_forward.w_1.bias torch.Size([2048])\n",
      "decoder.decoders.2.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "decoder.decoders.2.feed_forward.w_2.bias torch.Size([256])\n",
      "decoder.decoders.2.norm1.weight torch.Size([256])\n",
      "decoder.decoders.2.norm1.bias torch.Size([256])\n",
      "decoder.decoders.2.norm2.weight torch.Size([256])\n",
      "decoder.decoders.2.norm2.bias torch.Size([256])\n",
      "decoder.decoders.2.norm3.weight torch.Size([256])\n",
      "decoder.decoders.2.norm3.bias torch.Size([256])\n",
      "decoder.decoders.3.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.3.self_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.3.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.3.self_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.3.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.3.self_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.3.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.3.self_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.3.src_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.3.src_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.3.src_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.3.src_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.3.src_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.3.src_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.3.src_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.3.src_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.3.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "decoder.decoders.3.feed_forward.w_1.bias torch.Size([2048])\n",
      "decoder.decoders.3.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "decoder.decoders.3.feed_forward.w_2.bias torch.Size([256])\n",
      "decoder.decoders.3.norm1.weight torch.Size([256])\n",
      "decoder.decoders.3.norm1.bias torch.Size([256])\n",
      "decoder.decoders.3.norm2.weight torch.Size([256])\n",
      "decoder.decoders.3.norm2.bias torch.Size([256])\n",
      "decoder.decoders.3.norm3.weight torch.Size([256])\n",
      "decoder.decoders.3.norm3.bias torch.Size([256])\n",
      "decoder.decoders.4.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.4.self_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.4.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.4.self_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.4.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.4.self_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.4.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.4.self_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.4.src_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.4.src_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.4.src_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.4.src_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.4.src_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.4.src_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.4.src_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.4.src_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.4.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "decoder.decoders.4.feed_forward.w_1.bias torch.Size([2048])\n",
      "decoder.decoders.4.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "decoder.decoders.4.feed_forward.w_2.bias torch.Size([256])\n",
      "decoder.decoders.4.norm1.weight torch.Size([256])\n",
      "decoder.decoders.4.norm1.bias torch.Size([256])\n",
      "decoder.decoders.4.norm2.weight torch.Size([256])\n",
      "decoder.decoders.4.norm2.bias torch.Size([256])\n",
      "decoder.decoders.4.norm3.weight torch.Size([256])\n",
      "decoder.decoders.4.norm3.bias torch.Size([256])\n",
      "decoder.decoders.5.self_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.5.self_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.5.self_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.5.self_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.5.self_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.5.self_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.5.self_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.5.self_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.5.src_attn.linear_q.weight torch.Size([256, 256])\n",
      "decoder.decoders.5.src_attn.linear_q.bias torch.Size([256])\n",
      "decoder.decoders.5.src_attn.linear_k.weight torch.Size([256, 256])\n",
      "decoder.decoders.5.src_attn.linear_k.bias torch.Size([256])\n",
      "decoder.decoders.5.src_attn.linear_v.weight torch.Size([256, 256])\n",
      "decoder.decoders.5.src_attn.linear_v.bias torch.Size([256])\n",
      "decoder.decoders.5.src_attn.linear_out.weight torch.Size([256, 256])\n",
      "decoder.decoders.5.src_attn.linear_out.bias torch.Size([256])\n",
      "decoder.decoders.5.feed_forward.w_1.weight torch.Size([2048, 256])\n",
      "decoder.decoders.5.feed_forward.w_1.bias torch.Size([2048])\n",
      "decoder.decoders.5.feed_forward.w_2.weight torch.Size([256, 2048])\n",
      "decoder.decoders.5.feed_forward.w_2.bias torch.Size([256])\n",
      "decoder.decoders.5.norm1.weight torch.Size([256])\n",
      "decoder.decoders.5.norm1.bias torch.Size([256])\n",
      "decoder.decoders.5.norm2.weight torch.Size([256])\n",
      "decoder.decoders.5.norm2.bias torch.Size([256])\n",
      "decoder.decoders.5.norm3.weight torch.Size([256])\n",
      "decoder.decoders.5.norm3.bias torch.Size([256])\n",
      "ctc.ctc_lo.weight torch.Size([4234, 256])\n",
      "ctc.ctc_lo.bias torch.Size([4234])\n",
      "predictor.cif_conv1d.weight torch.Size([256, 1, 3])\n",
      "predictor.cif_conv1d.bias torch.Size([256])\n",
      "predictor.cif_output.weight torch.Size([1, 256])\n",
      "predictor.cif_output.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for k, v in ori_model.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0694,  0.1118, -0.1225],\n",
       "          [-0.1910, -0.2817, -0.0718],\n",
       "          [ 0.0752,  0.5253,  0.0259]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0941,  0.0088,  0.0016],\n",
       "          [-0.2821, -0.3845, -0.4264],\n",
       "          [ 0.1814,  0.3597,  0.4021]]],\n",
       "\n",
       "\n",
       "        [[[-0.0278,  0.0146, -0.0486],\n",
       "          [ 0.0695, -0.1283,  0.1437],\n",
       "          [-0.0627,  0.0071,  0.0517]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.2822,  0.1598,  0.1812],\n",
       "          [ 0.1314,  0.0064, -0.0921],\n",
       "          [ 0.0618,  0.0866, -0.2096]]],\n",
       "\n",
       "\n",
       "        [[[-0.1399,  0.1266, -0.0588],\n",
       "          [-0.0748,  0.0359,  0.0201],\n",
       "          [ 0.2022, -0.1038, -0.0025]]],\n",
       "\n",
       "\n",
       "        [[[-0.0575, -0.1556,  0.1342],\n",
       "          [ 0.2958, -0.4204,  0.1877],\n",
       "          [-0.0908, -0.3353,  0.4343]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_model[\"encoder.embed.conv.0.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0694,  0.1118, -0.1225],\n",
       "          [-0.1910, -0.2817, -0.0718],\n",
       "          [ 0.0752,  0.5253,  0.0259]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0941,  0.0088,  0.0016],\n",
       "          [-0.2821, -0.3845, -0.4264],\n",
       "          [ 0.1814,  0.3597,  0.4021]]],\n",
       "\n",
       "\n",
       "        [[[-0.0278,  0.0146, -0.0486],\n",
       "          [ 0.0695, -0.1283,  0.1437],\n",
       "          [-0.0627,  0.0071,  0.0517]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.2822,  0.1598,  0.1812],\n",
       "          [ 0.1314,  0.0064, -0.0921],\n",
       "          [ 0.0618,  0.0866, -0.2096]]],\n",
       "\n",
       "\n",
       "        [[[-0.1399,  0.1266, -0.0588],\n",
       "          [-0.0748,  0.0359,  0.0201],\n",
       "          [ 0.2022, -0.1038, -0.0025]]],\n",
       "\n",
       "\n",
       "        [[[-0.0575, -0.1556,  0.1342],\n",
       "          [ 0.2958, -0.4204,  0.1877],\n",
       "          [-0.0908, -0.3353,  0.4343]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"encoder.embed.conv.0.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "funasr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
