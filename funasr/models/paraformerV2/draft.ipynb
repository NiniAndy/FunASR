{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-18T01:55:31.465347Z",
     "start_time": "2024-11-18T01:55:31.382231Z"
    }
   },
   "source": [
    "from fast_ctc_decode import beam_search, viterbi_search\n",
    "import numpy as np\n",
    "\n",
    "alphabet = \"NACGT\"\n",
    "posteriors = np.random.rand(100, len(alphabet)).astype(np.float32)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T01:55:31.481871Z",
     "start_time": "2024-11-18T01:55:31.467261Z"
    }
   },
   "cell_type": "code",
   "source": "posteriors",
   "id": "14a7562175e43dde",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.51403725e-01, 1.61661133e-01, 7.16122389e-01, 6.76492035e-01,\n",
       "        7.12646186e-01],\n",
       "       [2.22872019e-01, 7.99192190e-01, 3.48819584e-01, 4.67524767e-01,\n",
       "        5.25442898e-01],\n",
       "       [9.26956636e-05, 8.37850153e-01, 4.44912702e-01, 4.39322054e-01,\n",
       "        5.44991255e-01],\n",
       "       [5.08055687e-01, 9.15716112e-01, 8.36381197e-01, 6.45499155e-02,\n",
       "        1.87459681e-02],\n",
       "       [6.58738732e-01, 3.08092177e-01, 9.05939281e-01, 2.87789077e-01,\n",
       "        7.01891243e-01],\n",
       "       [6.45718258e-03, 1.91067383e-01, 3.46876889e-01, 1.67837799e-01,\n",
       "        1.50810614e-01],\n",
       "       [3.03525120e-01, 5.69677413e-01, 1.59781054e-01, 9.50392783e-01,\n",
       "        3.75818610e-02],\n",
       "       [4.19730663e-01, 1.86281219e-01, 5.05963445e-01, 4.80880558e-01,\n",
       "        4.10791814e-01],\n",
       "       [5.03761768e-01, 4.12014693e-01, 1.53879330e-01, 6.86551988e-01,\n",
       "        5.07341902e-05],\n",
       "       [3.04291211e-02, 8.89865234e-02, 1.66581005e-01, 6.24630041e-02,\n",
       "        7.03654826e-01],\n",
       "       [4.64872211e-01, 5.53187788e-01, 2.74513930e-01, 6.97329700e-01,\n",
       "        8.03980350e-01],\n",
       "       [9.66233015e-01, 5.99712908e-01, 1.59457520e-01, 3.12990785e-01,\n",
       "        4.00109202e-01],\n",
       "       [9.76329446e-01, 5.98981261e-01, 7.62988329e-01, 4.21229482e-01,\n",
       "        5.44245422e-01],\n",
       "       [3.87422711e-01, 5.12566388e-01, 3.23150367e-01, 9.62216794e-01,\n",
       "        9.96034205e-01],\n",
       "       [1.73640221e-01, 4.05565292e-01, 1.94310285e-02, 4.11198586e-01,\n",
       "        1.09415963e-01],\n",
       "       [2.33967155e-01, 1.10677510e-01, 8.59586179e-01, 1.80993393e-01,\n",
       "        6.11744583e-01],\n",
       "       [9.26277995e-01, 7.30000734e-01, 2.63570249e-01, 4.51166004e-01,\n",
       "        3.77761066e-01],\n",
       "       [2.88014770e-01, 8.63176823e-01, 8.58866274e-01, 4.44453120e-01,\n",
       "        2.97422081e-01],\n",
       "       [2.20199689e-01, 1.43809110e-01, 5.00913382e-01, 6.19987622e-02,\n",
       "        8.40675116e-01],\n",
       "       [1.37408867e-01, 6.08957946e-01, 4.23712820e-01, 7.55585015e-01,\n",
       "        6.09500825e-01],\n",
       "       [4.91389245e-01, 4.83379573e-01, 2.38573417e-01, 2.59762108e-02,\n",
       "        4.74620849e-01],\n",
       "       [4.36051220e-01, 8.04579198e-01, 6.31802715e-04, 3.85913134e-01,\n",
       "        8.30833733e-01],\n",
       "       [9.69111264e-01, 6.37001574e-01, 3.73559952e-01, 5.14665306e-01,\n",
       "        3.83781046e-01],\n",
       "       [6.58156276e-01, 7.52477646e-01, 1.98678464e-01, 7.30918109e-01,\n",
       "        9.01995182e-01],\n",
       "       [3.18016738e-01, 9.95822549e-01, 9.60262656e-01, 9.39779937e-01,\n",
       "        4.28871185e-01],\n",
       "       [9.41856444e-01, 5.13009787e-01, 2.43144184e-01, 2.18702376e-01,\n",
       "        6.46439493e-01],\n",
       "       [8.64841044e-01, 5.91422081e-01, 9.42284465e-01, 3.21493685e-01,\n",
       "        8.31801713e-01],\n",
       "       [4.99650925e-01, 6.10317886e-01, 4.77692366e-01, 3.06298077e-01,\n",
       "        6.31461143e-01],\n",
       "       [6.61068618e-01, 2.96955943e-01, 3.98940183e-02, 7.44837821e-01,\n",
       "        5.53334653e-01],\n",
       "       [4.43631351e-01, 1.90474868e-01, 4.99930382e-01, 1.56213596e-01,\n",
       "        8.54044855e-01],\n",
       "       [8.70838881e-01, 4.06317800e-01, 7.84850478e-01, 6.47766471e-01,\n",
       "        8.10047150e-01],\n",
       "       [4.36842054e-01, 7.68395305e-01, 4.32685688e-02, 6.85129911e-02,\n",
       "        2.39477798e-01],\n",
       "       [9.33275819e-01, 7.20867872e-01, 4.38804477e-01, 1.12016037e-01,\n",
       "        4.28405613e-01],\n",
       "       [6.14486575e-01, 2.89161026e-01, 9.48919117e-01, 6.04786813e-01,\n",
       "        6.75661206e-01],\n",
       "       [8.46835732e-01, 2.94970930e-01, 1.32898971e-01, 6.38819098e-01,\n",
       "        1.46135643e-01],\n",
       "       [1.53345540e-01, 9.01370108e-01, 6.72430024e-02, 1.10525087e-01,\n",
       "        2.21222758e-01],\n",
       "       [3.22565764e-01, 9.70707312e-02, 1.58828259e-01, 4.31008101e-01,\n",
       "        9.09361362e-01],\n",
       "       [6.03009835e-02, 1.16066717e-01, 3.59547228e-01, 3.49317849e-01,\n",
       "        7.08980083e-01],\n",
       "       [9.83598530e-02, 4.34643090e-01, 7.08727717e-01, 4.34395581e-01,\n",
       "        2.76189178e-01],\n",
       "       [5.52753448e-01, 4.57388520e-01, 6.83166087e-01, 8.55126739e-01,\n",
       "        7.72810698e-01],\n",
       "       [3.72518569e-01, 7.32653663e-02, 8.16011190e-01, 3.08022171e-01,\n",
       "        4.76457566e-01],\n",
       "       [7.79826820e-01, 6.33380532e-01, 6.61636114e-01, 3.59055191e-01,\n",
       "        1.64028823e-01],\n",
       "       [2.50818282e-01, 5.53291887e-02, 7.89227843e-01, 6.29340231e-01,\n",
       "        7.72484660e-01],\n",
       "       [9.40372467e-01, 6.70968354e-01, 1.39388770e-01, 1.99442416e-01,\n",
       "        2.82942057e-01],\n",
       "       [6.87990963e-01, 3.30500072e-03, 6.88479364e-01, 9.62020338e-01,\n",
       "        9.13094640e-01],\n",
       "       [2.68781573e-01, 1.12534955e-03, 3.34547162e-02, 2.43440703e-01,\n",
       "        6.24968052e-01],\n",
       "       [9.07882974e-02, 2.33149990e-01, 2.18941182e-01, 1.69062778e-01,\n",
       "        5.55826426e-01],\n",
       "       [1.13617353e-01, 6.32363617e-01, 8.09056282e-01, 6.00183666e-01,\n",
       "        5.40351123e-02],\n",
       "       [2.82628477e-01, 2.97311634e-01, 6.36515498e-01, 1.08398370e-01,\n",
       "        5.21112196e-02],\n",
       "       [4.20894682e-01, 5.11993885e-01, 3.03263843e-01, 1.39774326e-02,\n",
       "        2.46414304e-01],\n",
       "       [1.02972254e-01, 8.57107699e-01, 3.13518256e-01, 9.05386090e-01,\n",
       "        8.39642823e-01],\n",
       "       [2.06914008e-01, 9.47653890e-01, 8.61648798e-01, 6.01146594e-02,\n",
       "        6.97749704e-02],\n",
       "       [3.23713981e-02, 2.72993237e-01, 3.02137136e-01, 7.20110953e-01,\n",
       "        9.49636996e-01],\n",
       "       [8.92310202e-01, 7.13813305e-01, 4.35257792e-01, 5.62970281e-01,\n",
       "        5.72635233e-01],\n",
       "       [5.24832845e-01, 6.17449760e-01, 4.30730432e-01, 2.63574511e-01,\n",
       "        2.40563691e-01],\n",
       "       [3.42664629e-01, 8.86823893e-01, 9.79520619e-01, 5.86002052e-01,\n",
       "        8.07984233e-01],\n",
       "       [2.21246973e-01, 7.56027579e-01, 1.78693444e-01, 9.23628569e-01,\n",
       "        8.56261849e-01],\n",
       "       [7.58351684e-01, 2.03204319e-01, 9.70181543e-03, 7.46084690e-01,\n",
       "        8.99251029e-02],\n",
       "       [2.68134534e-01, 3.45165938e-01, 1.33797348e-01, 1.22535683e-01,\n",
       "        2.26471238e-02],\n",
       "       [2.22107217e-01, 4.13302302e-01, 1.77781746e-01, 4.36648093e-02,\n",
       "        2.04590037e-01],\n",
       "       [3.41955900e-01, 1.00311771e-01, 9.44922805e-01, 9.90851760e-01,\n",
       "        3.85331750e-01],\n",
       "       [1.00411966e-01, 9.70278144e-01, 1.10601440e-01, 1.72385767e-01,\n",
       "        7.22609699e-01],\n",
       "       [4.39120829e-01, 5.90649307e-01, 4.05903190e-01, 7.16645181e-01,\n",
       "        9.40411329e-01],\n",
       "       [5.17944545e-02, 7.07504272e-01, 9.52865541e-01, 6.14536941e-01,\n",
       "        5.68418801e-01],\n",
       "       [9.61772203e-01, 8.22825253e-01, 6.30160987e-01, 4.12157893e-01,\n",
       "        3.48559499e-01],\n",
       "       [7.21724451e-01, 6.80039704e-01, 4.91982281e-01, 5.98945200e-01,\n",
       "        7.25856066e-01],\n",
       "       [8.69833589e-01, 4.15918589e-01, 4.28029120e-01, 6.17504001e-01,\n",
       "        6.94309890e-01],\n",
       "       [5.85611872e-02, 6.54035628e-01, 8.56308460e-01, 2.59715974e-01,\n",
       "        3.14951062e-01],\n",
       "       [5.55361450e-01, 6.75379515e-01, 2.51838028e-01, 4.82949167e-01,\n",
       "        7.37203658e-01],\n",
       "       [6.98460937e-01, 5.73259354e-01, 4.29309756e-01, 3.92939121e-01,\n",
       "        2.55801290e-01],\n",
       "       [8.49424303e-01, 5.66520929e-01, 9.39421117e-01, 1.04614459e-01,\n",
       "        8.11205089e-01],\n",
       "       [5.67432009e-02, 6.72259390e-01, 6.05594292e-02, 7.54195526e-02,\n",
       "        3.99909616e-01],\n",
       "       [9.35269773e-01, 3.73174518e-01, 1.15614142e-02, 5.21937490e-01,\n",
       "        5.75473070e-01],\n",
       "       [3.11269581e-01, 8.70018125e-01, 2.94096887e-01, 4.83861178e-01,\n",
       "        2.72787988e-01],\n",
       "       [9.28128123e-01, 5.78529477e-01, 8.37860882e-01, 8.82652760e-01,\n",
       "        4.97396439e-01],\n",
       "       [6.45734072e-01, 9.19670582e-01, 3.91091138e-01, 3.54829729e-01,\n",
       "        5.69814086e-01],\n",
       "       [7.75915444e-01, 5.32057822e-01, 7.85473108e-01, 1.07709751e-01,\n",
       "        5.19332945e-01],\n",
       "       [2.40057915e-01, 7.11414278e-01, 5.84427893e-01, 1.14045814e-01,\n",
       "        4.12618369e-01],\n",
       "       [7.27608323e-01, 8.86885345e-01, 6.99005902e-01, 3.80459845e-01,\n",
       "        5.38429081e-01],\n",
       "       [4.69107777e-01, 7.08915532e-01, 3.09937388e-01, 8.97318184e-01,\n",
       "        2.48089015e-01],\n",
       "       [1.41433597e-01, 1.38536990e-02, 8.49636078e-01, 2.78904855e-01,\n",
       "        7.74021566e-01],\n",
       "       [8.48702252e-01, 2.27192566e-01, 7.22778678e-01, 1.53740957e-01,\n",
       "        6.39449656e-01],\n",
       "       [4.45120245e-01, 3.21305484e-01, 8.99423301e-01, 1.34628817e-01,\n",
       "        9.10722375e-01],\n",
       "       [7.20705688e-02, 8.65245283e-01, 9.94383693e-01, 5.25742948e-01,\n",
       "        9.18299079e-01],\n",
       "       [7.77481556e-01, 5.64966142e-01, 4.81028594e-02, 2.74281204e-01,\n",
       "        2.02874735e-01],\n",
       "       [3.40922654e-01, 2.38893047e-01, 4.83723879e-01, 7.00183511e-01,\n",
       "        9.21916664e-01],\n",
       "       [8.37209582e-01, 5.84642768e-01, 8.53627026e-01, 5.73239028e-01,\n",
       "        5.43702245e-01],\n",
       "       [4.04553294e-01, 3.34621936e-01, 5.45793653e-01, 6.99660838e-01,\n",
       "        4.37570035e-01],\n",
       "       [7.84820974e-01, 1.91091344e-01, 9.39578414e-02, 7.95675516e-01,\n",
       "        8.07005167e-01],\n",
       "       [4.10801142e-01, 9.26896453e-01, 4.60669398e-01, 6.45825267e-01,\n",
       "        4.18686122e-01],\n",
       "       [9.14807916e-01, 8.36713850e-01, 6.20354891e-01, 9.99356210e-01,\n",
       "        7.30319440e-01],\n",
       "       [6.79668844e-01, 2.19002381e-01, 6.57906830e-01, 4.13725853e-01,\n",
       "        1.44956753e-01],\n",
       "       [5.93845993e-02, 3.86696756e-01, 1.57737449e-01, 1.05293132e-01,\n",
       "        3.06811109e-02],\n",
       "       [7.07448840e-01, 2.16094360e-01, 4.00037885e-01, 3.24906647e-01,\n",
       "        6.22229695e-01],\n",
       "       [1.67866629e-02, 9.78260338e-02, 8.85990024e-01, 9.65302110e-01,\n",
       "        2.72864789e-01],\n",
       "       [6.72142148e-01, 9.16089416e-01, 5.54984435e-02, 5.89955330e-01,\n",
       "        3.40501487e-01],\n",
       "       [2.99065292e-01, 7.70696402e-01, 9.88586307e-01, 2.26218894e-01,\n",
       "        3.51238161e-01],\n",
       "       [7.93653309e-01, 1.56117573e-01, 9.79729533e-01, 8.37473869e-01,\n",
       "        9.47627187e-01],\n",
       "       [1.23277947e-01, 3.58728856e-01, 8.31065238e-01, 3.72744888e-01,\n",
       "        6.63063288e-01],\n",
       "       [8.08385730e-01, 2.13687718e-01, 3.72642994e-01, 1.41231284e-01,\n",
       "        4.75203276e-01]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T01:55:33.094601Z",
     "start_time": "2024-11-18T01:55:33.086043Z"
    }
   },
   "cell_type": "code",
   "source": "seq, path = viterbi_search(posteriors, alphabet)",
   "id": "8a61620221e5fe75",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T01:55:33.720812Z",
     "start_time": "2024-11-18T01:55:33.712748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print (seq)\n",
    "print (path)"
   ],
   "id": "293786a01457b822",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CACGCGTTGCATGTTACTGTACATCGCCGTCAGATACGAGATCTCTCAAACAGCTCTCGTAGAGAC\n",
      "[0, 1, 4, 6, 7, 8, 9, 13, 14, 15, 17, 18, 19, 21, 23, 24, 26, 27, 28, 29, 31, 33, 35, 36, 38, 39, 40, 42, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 58, 60, 61, 62, 63, 65, 67, 68, 70, 71, 73, 75, 76, 77, 79, 80, 82, 83, 85, 86, 87, 88, 89, 90, 92, 94, 95, 96]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T01:55:34.305081Z",
     "start_time": "2024-11-18T01:55:34.294236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seq, path = beam_search(posteriors, alphabet, beam_size=5, beam_cut_threshold=0.1)\n",
    "seq"
   ],
   "id": "bd50716c15ec02f4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CACGTGTCTAGATAGATCTCTCACTAGAGATCTAGACTATGAGAGATC'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T01:55:34.910317Z",
     "start_time": "2024-11-18T01:55:34.893830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def viterbi_alignment(ctc_probs, text, blank=0):\n",
    "    B, T, N = ctc_probs.shape  # Batch size, time steps, vocab size\n",
    "    U = text.shape[1]  # Target sequence length\n",
    "    \n",
    "    alignments = []\n",
    "    for b in range(B):  # Process each batch individually\n",
    "        # Step 1: Extend target sequence with blanks\n",
    "        ext_text = [blank]\n",
    "        for token in text[b]:\n",
    "            ext_text.append(token)\n",
    "            ext_text.append(blank)\n",
    "        ext_U = len(ext_text)\n",
    "\n",
    "        # Step 2: Initialize DP table\n",
    "        dp = np.full((T, ext_U), -np.inf)\n",
    "        dp[0][0] = np.log(ctc_probs[b, 0, blank])\n",
    "        dp[0][1] = np.log(ctc_probs[b, 0, text[b, 0]])\n",
    "\n",
    "        # Step 3: Fill DP table\n",
    "        for t in range(1, T):\n",
    "            for s in range(ext_U):\n",
    "                stay = dp[t - 1][s]\n",
    "                move = dp[t - 1][s - 1] if s > 0 else -np.inf\n",
    "                skip = dp[t - 1][s - 2] if s > 1 and ext_text[s] != blank and ext_text[s] != ext_text[s - 2] else -np.inf\n",
    "                \n",
    "                dp[t][s] = np.log(ctc_probs[b, t, ext_text[s]]) + max(stay, move, skip)\n",
    "\n",
    "        # Step 4: Backtrace to find alignment\n",
    "        alignment = []\n",
    "        s = np.argmax(dp[T - 1])  # Start from the best end state\n",
    "        for t in range(T - 1, -1, -1):\n",
    "            alignment.append(ext_text[s])\n",
    "            if s > 0 and dp[t][s] == dp[t - 1][s - 1] + np.log(ctc_probs[b, t, ext_text[s]]):\n",
    "                s -= 1\n",
    "            elif s > 1 and dp[t][s] == dp[t - 1][s - 2] + np.log(ctc_probs[b, t, ext_text[s]]):\n",
    "                s -= 2\n",
    "        alignments.append(alignment[::-1])  # Reverse alignment\n",
    "\n",
    "    return alignments"
   ],
   "id": "b42ca4bb992e04db",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T01:55:37.122252Z",
     "start_time": "2024-11-18T01:55:35.606435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def viterbi_alignment_torch(ctc_probs, text, blank=0):\n",
    "    \"\"\"\n",
    "    Viterbi alignment for CTC probabilities using PyTorch.\n",
    "\n",
    "    Args:\n",
    "        ctc_probs (torch.Tensor): Shape [B, T, N], CTC probabilities (already log-softmaxed).\n",
    "        text (torch.Tensor): Shape [B, U], target sequences.\n",
    "        blank (int): Index of the blank token in the vocabulary.\n",
    "\n",
    "    Returns:\n",
    "        List[List[int]]: A list of alignment paths for each batch.\n",
    "    \"\"\"\n",
    "    B, T, N = ctc_probs.size()  # Batch size, time steps, vocab size\n",
    "    U = text.size(1)  # Target sequence length\n",
    "\n",
    "    alignments = []\n",
    "\n",
    "    for b in range(B):  # Process each batch individually\n",
    "        # Step 1: Extend target sequence with blanks\n",
    "        ext_text = [blank]\n",
    "        for token in text[b]:\n",
    "            ext_text.append(token.item())\n",
    "            ext_text.append(blank)\n",
    "        ext_U = len(ext_text)\n",
    "\n",
    "        # Step 2: Initialize DP table\n",
    "        dp = torch.full((T, ext_U), -float('inf'), device=ctc_probs.device)  # DP table\n",
    "        dp[0, 0] = ctc_probs[b, 0, blank]  # Start with blank\n",
    "        if ext_U > 1:\n",
    "            dp[0, 1] = ctc_probs[b, 0, text[b, 0]]  # First token\n",
    "\n",
    "        # Step 3: Fill DP table\n",
    "        for t in range(1, T):\n",
    "            for s in range(ext_U):\n",
    "                # Calculate scores for stay, move, and skip transitions\n",
    "                stay = dp[t - 1, s]\n",
    "                move = dp[t - 1, s - 1] if s > 0 else -float('inf')\n",
    "                skip = dp[t - 1, s - 2] if s > 1 and ext_text[s] != blank and ext_text[s] != ext_text[s - 2] else -float('inf')\n",
    "\n",
    "                dp[t, s] = ctc_probs[b, t, ext_text[s]] + torch.logsumexp(torch.tensor([stay, move, skip], device=ctc_probs.device), dim=0)\n",
    "\n",
    "        # Step 4: Backtrace to find alignment\n",
    "        alignment = []\n",
    "        s = torch.argmax(dp[T - 1]).item()  # Start from the best end state\n",
    "        for t in range(T - 1, -1, -1):\n",
    "            alignment.append(ext_text[s])\n",
    "            if s > 0 and dp[t, s] == dp[t - 1, s - 1] + ctc_probs[b, t, ext_text[s]]:\n",
    "                s -= 1\n",
    "            elif s > 1 and dp[t, s] == dp[t - 1, s - 2] + ctc_probs[b, t, ext_text[s]]:\n",
    "                s -= 2\n",
    "        alignments.append(alignment[::-1])  # Reverse alignment\n",
    "\n",
    "    return alignments"
   ],
   "id": "ccc32950262b3734",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T01:55:38.006883Z",
     "start_time": "2024-11-18T01:55:37.962591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = np.array([[1, 2], [3, 4]], dtype=np.int32)\n",
    "ctc_probs = np.random.rand(2, 10, 10).astype(np.float32)\n",
    "text_tensor = torch.tensor(text)\n",
    "ctc_probs_tensor = torch.tensor(ctc_probs)\n",
    "print(viterbi_alignment_torch(ctc_probs_tensor, text_tensor))\n",
    "print(viterbi_alignment(ctc_probs, text))"
   ],
   "id": "50972cbc07fe5459",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 0, 0, 0, 0, 0, 0, 0, 0], [3, 4, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "[[np.int32(1), 0, 0, 0, np.int32(2), np.int32(2), np.int32(2), np.int32(2), np.int32(2), 0], [0, 0, 0, 0, np.int32(3), np.int32(3), np.int32(3), 0, np.int32(4), np.int32(4)]]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T01:55:38.726011Z",
     "start_time": "2024-11-18T01:55:38.714896Z"
    }
   },
   "cell_type": "code",
   "source": "viterbi_alignment(ctc_probs, text)",
   "id": "8a6881f5be0abe09",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[np.int32(1),\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  np.int32(2),\n",
       "  np.int32(2),\n",
       "  np.int32(2),\n",
       "  np.int32(2),\n",
       "  np.int32(2),\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  np.int32(3),\n",
       "  np.int32(3),\n",
       "  np.int32(3),\n",
       "  0,\n",
       "  np.int32(4),\n",
       "  np.int32(4)]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T01:55:39.429461Z",
     "start_time": "2024-11-18T01:55:39.412402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def ctc_viterbi_align(ctc_probs, texts, blank_id=0, pad_id=-1):\n",
    "    \"\"\"\n",
    "    ctc_probs: Tensor [B, T, N]，CTC 后验概率（对数概率）。\n",
    "    texts: Tensor [B, U]，经过填充的目标序列。\n",
    "    返回：\n",
    "    alignments: List，每个元素是长度为 T 的对齐路径（列表形式）。\n",
    "    \"\"\"\n",
    "    B, T, N = ctc_probs.size()\n",
    "    _, U = texts.size()\n",
    "    alignments = []\n",
    "\n",
    "    # 对于批次中的每个样本\n",
    "    for b in range(B):\n",
    "        # 1. 获取实际的目标序列，移除填充\n",
    "        text = texts[b]\n",
    "        text = text[text != pad_id]  # 移除填充\n",
    "        text = text.cpu().numpy().tolist()\n",
    "        \n",
    "        # 2. 扩展目标序列，在每个标签之间和首尾插入 blank\n",
    "        extended_seq = []\n",
    "        for token in text:\n",
    "            extended_seq.append(blank_id)\n",
    "            extended_seq.append(token)\n",
    "        extended_seq.append(blank_id)\n",
    "        # extended_seq: [blank, l1, blank, l2, blank, ..., ln, blank]\n",
    "        L = len(extended_seq)\n",
    "        \n",
    "        # 3. 获取该样本的 CTC 概率（取对数以避免下溢）\n",
    "        log_probs = ctc_probs[b].log()  # [T, N]\n",
    "        log_probs = log_probs.cpu().numpy()\n",
    "        \n",
    "        # 4. 初始化动态规划矩阵\n",
    "        dp = -float('inf') * np.ones((T, L), dtype=np.float32)  # [T, L]\n",
    "        ptr = -np.ones((T, L), dtype=int)  # 用于回溯路径\n",
    "\n",
    "        # 初始化第一个时间步\n",
    "        dp[0, 0] = log_probs[0, blank_id]  # blank\n",
    "        if L > 1:\n",
    "            dp[0, 1] = log_probs[0, extended_seq[1]]  # 第一个标签\n",
    "\n",
    "        # 5. 动态规划递推\n",
    "        for t in range(1, T):\n",
    "            for s in range(L):\n",
    "                current_label = extended_seq[s]\n",
    "                prob = log_probs[t, current_label]\n",
    "\n",
    "                # 来自 s\n",
    "                candidates = [dp[t-1, s]]\n",
    "                # 来自 s-1\n",
    "                if s > 0:\n",
    "                    candidates.append(dp[t-1, s-1])\n",
    "                # 来自 s-2（避免重复标签）\n",
    "                if s > 1 and extended_seq[s] != blank_id and extended_seq[s] != extended_seq[s-2]:\n",
    "                    candidates.append(dp[t-1, s-2])\n",
    "                \n",
    "                max_prev = max(candidates)\n",
    "                dp[t, s] = max_prev + prob\n",
    "\n",
    "                # 记录回溯指针\n",
    "                if max_prev == dp[t-1, s]:\n",
    "                    ptr[t, s] = s\n",
    "                elif s > 0 and max_prev == dp[t-1, s-1]:\n",
    "                    ptr[t, s] = s - 1\n",
    "                elif s > 1 and max_prev == dp[t-1, s-2]:\n",
    "                    ptr[t, s] = s - 2\n",
    "\n",
    "        # 6. 回溯找到最优路径\n",
    "        # 从最后一个时间步和状态开始\n",
    "        s = np.argmax(dp[T-1, :])\n",
    "        alignment = []\n",
    "        for t in range(T-1, -1, -1):\n",
    "            alignment.append(extended_seq[s])\n",
    "            s = ptr[t, s]\n",
    "            if s == -1:\n",
    "                break\n",
    "        alignment = alignment[::-1]  # 逆序\n",
    "        # 将对齐结果扩展到长度为 T\n",
    "        if len(alignment) < T:\n",
    "            alignment = [blank_id] * (T - len(alignment)) + alignment\n",
    "\n",
    "        alignments.append(alignment)\n",
    "\n",
    "    return alignments"
   ],
   "id": "4a003fe6734c76ae",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T01:55:40.368146Z",
     "start_time": "2024-11-18T01:55:40.349726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = np.array([[3, 4, 5, 6]], dtype=np.int32)\n",
    "ctc_probs = np.random.rand(1, 10, 10).astype(np.float32)\n",
    "text_tensor = torch.tensor(text)\n",
    "ctc_probs_tensor = torch.tensor(ctc_probs)\n",
    "print(viterbi_alignment_torch(ctc_probs_tensor, text_tensor))\n",
    "print( [[int(x) for x in sublist] for sublist in viterbi_alignment(ctc_probs, text)])\n",
    "print (ctc_viterbi_align(ctc_probs_tensor, text_tensor, blank_id=0, pad_id=-1))\n"
   ],
   "id": "e97b2f88b60a3d4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 4, 5, 6, 6, 6, 6, 6, 6, 6]]\n",
      "[[3, 3, 3, 0, 4, 5, 0, 6, 6, 6]]\n",
      "[[3, 3, 3, 0, 4, 5, 0, 6, 6, 6]]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T01:55:41.198610Z",
     "start_time": "2024-11-18T01:55:41.184040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ctc_viterbi_align(ctc_prob, text_b, blank_id=0, pad_id=-1):\n",
    "    T = ctc_prob.shape[0]  # 时间步数\n",
    "    N = len(text_b)  # 目标序列的长度\n",
    "    dp = np.zeros((T, N + 1))  # dp[t][i] -> 第 t 个时间步，第 i 个目标标签的最大概率\n",
    "    path = np.zeros((T, N + 1), dtype=int)  # 用于回溯路径\n",
    "    \n",
    "    # 初始状态\n",
    "    dp[0, 0] = ctc_prob[0, blank_id]  # 初始为空白标签的概率\n",
    "    for i in range(1, N + 1):\n",
    "        dp[0, i] = ctc_prob[0, text_b[i - 1]]  # 初始化第一个目标标签\n",
    "    \n",
    "    # 递归动态规划\n",
    "    for t in range(1, T):\n",
    "        for i in range(N + 1):\n",
    "            if i == 0:\n",
    "                dp[t, i] = dp[t - 1, 0] * ctc_prob[t, blank_id]  # 继续选择空白标签\n",
    "                path[t, i] = 0\n",
    "            else:\n",
    "                # 路径1：选择前一个标签对应的对齐路径\n",
    "                score1 = dp[t - 1, i - 1] * ctc_prob[t, text_b[i - 1]]\n",
    "                # 路径2：选择空白标签\n",
    "                score2 = dp[t - 1, i] * ctc_prob[t, blank_id]\n",
    "                if score1 > score2:\n",
    "                    dp[t, i] = score1\n",
    "                    path[t, i] = i - 1\n",
    "                else:\n",
    "                    dp[t, i] = score2\n",
    "                    path[t, i] = i\n",
    "    \n",
    "    # 回溯路径\n",
    "    best_path = []\n",
    "    t = T - 1\n",
    "    i = N\n",
    "    while t >= 0 and i >= 0:\n",
    "        best_path.append(text_b[i - 1] if i > 0 else blank_id)\n",
    "        i = path[t, i]\n",
    "        t -= 1\n",
    "    \n",
    "    best_path = best_path[::-1]  # 反转路径\n",
    "    return best_path"
   ],
   "id": "d66a37efcba764c5",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T01:55:42.060023Z",
     "start_time": "2024-11-18T01:55:42.050843Z"
    }
   },
   "cell_type": "code",
   "source": "ctc_viterbi_align(ctc_probs[0], text[0])",
   "id": "3cea0bab7f4b76f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int32(3),\n",
       " np.int32(3),\n",
       " np.int32(4),\n",
       " np.int32(4),\n",
       " np.int32(4),\n",
       " np.int32(5),\n",
       " np.int32(5),\n",
       " np.int32(5),\n",
       " np.int32(6),\n",
       " np.int32(6)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T01:55:43.458001Z",
     "start_time": "2024-11-18T01:55:43.440400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def insert_blank(label, blank_id=0):\n",
    "    \"\"\"Insert blank token between every two label token.\"\"\"\n",
    "    label = np.expand_dims(label, 1)\n",
    "    blanks = np.zeros((label.shape[0], 1), dtype=np.int64) + blank_id\n",
    "    label = np.concatenate([blanks, label], axis=1)\n",
    "    label = label.reshape(-1)\n",
    "    label = np.append(label, label[0])\n",
    "    return label\n",
    "\n",
    "\n",
    "def force_align(ctc_probs: torch.Tensor, y: torch.Tensor, blank_id=0) -> list:\n",
    "    \"\"\"ctc forced alignment.\n",
    "\n",
    "    Args:\n",
    "        torch.Tensor ctc_probs: hidden state sequence, 2d tensor (T, D)\n",
    "        torch.Tensor y: id sequence tensor 1d tensor (L)\n",
    "        int blank_id: blank symbol index\n",
    "    Returns:\n",
    "        torch.Tensor: alignment result\n",
    "    \"\"\"\n",
    "    ctc_probs = ctc_probs.cpu()\n",
    "    y = y.cpu()\n",
    "    y_insert_blank = insert_blank(y, blank_id)\n",
    "\n",
    "    log_alpha = torch.zeros((ctc_probs.size(0), len(y_insert_blank)))\n",
    "    log_alpha = log_alpha - float('inf')  # log of zero\n",
    "    state_path = torch.zeros((ctc_probs.size(0), len(y_insert_blank)),\n",
    "                             dtype=torch.int16) - 1  # state path\n",
    "\n",
    "    # init start state\n",
    "    log_alpha[0, 0] = ctc_probs[0][y_insert_blank[0]]\n",
    "    log_alpha[0, 1] = ctc_probs[0][y_insert_blank[1]]\n",
    "\n",
    "    for t in range(1, ctc_probs.size(0)):\n",
    "        for s in range(len(y_insert_blank)):\n",
    "            if y_insert_blank[s] == blank_id or s < 2 or y_insert_blank[\n",
    "                    s] == y_insert_blank[s - 2]:\n",
    "                candidates = torch.tensor(\n",
    "                    [log_alpha[t - 1, s], log_alpha[t - 1, s - 1]])\n",
    "                prev_state = [s, s - 1]\n",
    "            else:\n",
    "                candidates = torch.tensor([\n",
    "                    log_alpha[t - 1, s],\n",
    "                    log_alpha[t - 1, s - 1],\n",
    "                    log_alpha[t - 1, s - 2],\n",
    "                ])\n",
    "                prev_state = [s, s - 1, s - 2]\n",
    "            log_alpha[\n",
    "                t, s] = torch.max(candidates) + ctc_probs[t][y_insert_blank[s]]\n",
    "            state_path[t, s] = prev_state[torch.argmax(candidates)]\n",
    "\n",
    "    state_seq = -1 * torch.ones((ctc_probs.size(0), 1), dtype=torch.int16)\n",
    "\n",
    "    candidates = torch.tensor([\n",
    "        log_alpha[-1, len(y_insert_blank) - 1],\n",
    "        log_alpha[-1, len(y_insert_blank) - 2]\n",
    "    ])\n",
    "    final_state = [len(y_insert_blank) - 1, len(y_insert_blank) - 2]\n",
    "    state_seq[-1] = final_state[torch.argmax(candidates)]\n",
    "    for t in range(ctc_probs.size(0) - 2, -1, -1):\n",
    "        state_seq[t] = state_path[t + 1, state_seq[t + 1, 0]]\n",
    "\n",
    "    output_alignment = []\n",
    "    for t in range(0, ctc_probs.size(0)):\n",
    "        output_alignment.append(y_insert_blank[state_seq[t, 0]])\n",
    "\n",
    "    return output_alignment"
   ],
   "id": "f236c694cf5517f6",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T02:36:28.624209Z",
     "start_time": "2024-11-18T02:36:28.584266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = np.array([[3, 4, 5, 6, 9]], dtype=np.int32)\n",
    "ctc_probs = np.random.rand(1, 20, 10).astype(np.float32)\n",
    "ctc_probs_tensor = torch.softmax(torch.tensor(ctc_probs), dim=-1)\n",
    "ctc_probs = ctc_probs_tensor.numpy()\n",
    "text_tensor = torch.tensor(text)\n",
    "ctc_probs_tensor = torch.tensor(ctc_probs)\n",
    "print(viterbi_alignment_torch(ctc_probs_tensor, text_tensor))\n",
    "print( [[int(x) for x in sublist] for sublist in viterbi_alignment(ctc_probs, text)])\n",
    "print ([int(x) for x in ctc_viterbi_align(ctc_probs[0], text[0])])\n",
    "print ([int(x) for x in force_align(ctc_probs_tensor[0], text_tensor[0])])"
   ],
   "id": "cedbc471764fa147",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 4, 5, 6, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "[[3, 3, 3, 0, 4, 0, 0, 0, 0, 5, 5, 5, 5, 5, 0, 6, 6, 6, 9, 9]]\n",
      "[0, 0, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 6, 6, 6, 9, 9]\n",
      "[3, 3, 3, 0, 4, 0, 0, 0, 0, 5, 5, 5, 5, 5, 0, 6, 6, 6, 9, 9]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T02:50:07.274468Z",
     "start_time": "2024-11-18T02:50:07.262113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ctc_prob = torch.load(\"/ssd/zhuang/code/FunASR/funasr/models/paraformerV2/ctc_prob\")\n",
    "text_b = torch.load(\"/ssd/zhuang/code/FunASR/funasr/models/paraformerV2/text_b\")"
   ],
   "id": "91730ce7bb841fc4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3106725/272666365.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ctc_prob = torch.load(\"/ssd/zhuang/code/FunASR/funasr/models/paraformerV2/ctc_prob\")\n",
      "/tmp/ipykernel_3106725/272666365.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  text_b = torch.load(\"/ssd/zhuang/code/FunASR/funasr/models/paraformerV2/text_b\")\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T02:50:16.982013Z",
     "start_time": "2024-11-18T02:50:16.969473Z"
    }
   },
   "cell_type": "code",
   "source": "ctc_prob",
   "id": "84a330a2473790f1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.0503, -8.2395, -9.9503,  ..., -7.9820, -7.8188, -8.6158],\n",
       "        [-7.4608, -9.0117, -9.1419,  ..., -7.0696, -7.5999, -8.3954],\n",
       "        [-7.8047, -8.6365, -9.6139,  ..., -7.0698, -7.8144, -8.3241],\n",
       "        ...,\n",
       "        [-8.3635, -9.0758, -9.6072,  ..., -8.0879, -9.0771, -8.6355],\n",
       "        [-8.2764, -8.7710, -9.4807,  ..., -8.2481, -8.0597, -8.5509],\n",
       "        [-7.8216, -9.5307, -9.6108,  ..., -8.0596, -8.9597, -8.7208]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "104665ece2b2f379"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "95389821c1194c4a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T02:50:40.090692Z",
     "start_time": "2024-11-18T02:50:39.922459Z"
    }
   },
   "cell_type": "code",
   "source": "print ([int(x) for x in force_align(ctc_prob, text_b)])",
   "id": "52cf5b4604927c02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1127, 0, 0, 1749, 0, 433, 37, 0, 0, 3066, 0, 0, 0, 814, 0, 0, 0, 0, 1380, 37, 37, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 0, 1015, 1276, 2554, 597, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 0, 0, 1127, 1749, 433, 37, 37, 3066, 3066, 814, 0, 0, 0, 0, 0, 1380, 1380, 1380, 1380, 0, 0, 37, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 4068, 1015, 1276, 2554, 597, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 2342, 0, 0]\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T08:25:00.348506Z",
     "start_time": "2024-11-18T08:25:00.333362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "def average_repeats(ctc_prob, alignment):\n",
    "    \"\"\"\n",
    "    Averages the repeated frames based on alignment without merging distinct occurrences of the same token.\n",
    "\n",
    "    Args:\n",
    "        ctc_prob (torch.Tensor): Tensor of shape [T, VocabSize + 1] representing frame-wise CTC posteriors.\n",
    "        alignment (torch.Tensor): Tensor of shape [T,] representing the target alignment from Viterbi algorithm.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Compressed CTC posterior with repeated frames averaged.\n",
    "    \"\"\"\n",
    "    unique_probs = []\n",
    "    current_sum = ctc_prob[0]\n",
    "    current_count = 1\n",
    "\n",
    "    for t in range(1, alignment.size(0)):\n",
    "        token = alignment[t].item()\n",
    "        prev_token = alignment[t - 1].item()\n",
    "        prob = ctc_prob[t]\n",
    "\n",
    "        if token == prev_token:\n",
    "            current_sum += prob\n",
    "            current_count += 1\n",
    "        else:\n",
    "            unique_probs.append(current_sum / current_count)\n",
    "            current_sum = prob\n",
    "            current_count = 1\n",
    "\n",
    "    # Append the last averaged probability\n",
    "    unique_probs.append(current_sum / current_count)\n",
    "\n",
    "    return torch.stack(unique_probs)\n",
    "\n",
    "def remove_blanks(ctc_prob, alignment):\n",
    "    \"\"\"\n",
    "    Removes blank tokens from the alignment and returns the corresponding CTC probabilities.\n",
    "\n",
    "    Args:\n",
    "        ctc_prob (torch.Tensor): Tensor of shape [U', VocabSize + 1] representing compressed CTC posteriors.\n",
    "        alignment (torch.Tensor): Tensor of shape [T,] representing the target alignment from Viterbi algorithm.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Compressed CTC posterior with blanks removed.\n",
    "    \"\"\"\n",
    "    non_blank_probs = []\n",
    "    non_blank_indices = []\n",
    "    idx = 0\n",
    "\n",
    "    for t in range(alignment.size(0)):\n",
    "        token = alignment[t].item()\n",
    "        if token != 0:  # 0 is assumed to be the blank token\n",
    "            non_blank_indices.append(idx)\n",
    "        if t == alignment.size(0) - 1 or alignment[t] != alignment[t + 1]:\n",
    "            idx += 1\n",
    "\n",
    "    for idx in non_blank_indices:\n",
    "        non_blank_probs.append(ctc_prob[idx])\n",
    "\n",
    "    return torch.stack(non_blank_probs)\n",
    "\n",
    "# Example usage\n",
    "ctc_prob = torch.randn(15, 100)  # Assume 15 frames, 100 vocabulary size + 1 blank\n",
    "alignment = torch.tensor([3797, 11, 3727, 3143, 72, 71, 4009, 4009, 4009, 1150, 2554, 3015, 1338, 339, 1452])\n",
    "\n",
    "compressed_ctc_prob = average_repeats(ctc_prob, alignment)\n",
    "non_blank_ctc_prob = remove_blanks(compressed_ctc_prob, alignment)\n",
    "print(non_blank_ctc_prob.size())"
   ],
   "id": "5257425959840a72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 100])\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9773387ddc1f3fa6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
